
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup
from sklearn.metrics import accuracy_score
from utils.database_utils.DatabaseMalwareDataset import StratifiedDatabaseMalwareDataset


class CustomTrainer:
    def __init__(self, model, train_dataset, val_dataset, tokenizer, device, learning_rate=5e-5, epochs=3, batch_size=8,
                 save_path='./best_model'):
        self.model = model.to(device)
        self.train_dataset = train_dataset
        self.val_dataset = val_dataset
        self.tokenizer = tokenizer
        self.device = device
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.batch_size = batch_size
        self.save_path = save_path
        self.best_val_accuracy = 0.0

        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.learning_rate)
        self.criterion = nn.CrossEntropyLoss()

        # Total number of training steps
        self.total_steps = len(train_dataset) // self.batch_size * self.epochs
        self.scheduler = get_linear_schedule_with_warmup(self.optimizer, num_warmup_steps=10,
                                                         num_training_steps=self.total_steps)

    def train_epoch(self, dataloader):
        self.model.train()
        total_loss = 0
        for batch in dataloader:
            self.optimizer.zero_grad()

            input_ids = batch['input_ids'].to(self.device)
            attention_mask = batch['attention_mask'].to(self.device)
            labels = batch['labels'].to(self.device)

            outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss

            total_loss += loss.item()
            loss.backward()
            self.optimizer.step()
            self.scheduler.step()

        avg_loss = total_loss / len(dataloader)
        return avg_loss

    def evaluate(self, dataloader):
        self.model.eval()
        total_eval_accuracy = 0
        for batch in dataloader:
            input_ids = batch['input_ids'].to(self.device)
            attention_mask = batch['attention_mask'].to(self.device)
            labels = batch['labels'].to(self.device)

            with torch.no_grad():
                outputs = self.model(input_ids, attention_mask=attention_mask)

            logits = outputs.logits
            predictions = torch.argmax(logits, dim=-1)
            total_eval_accuracy += accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())

        avg_val_accuracy = total_eval_accuracy / len(dataloader)
        return avg_val_accuracy

    def train(self):
        train_dataloader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)
        val_dataloader = DataLoader(self.val_dataset, batch_size=self.batch_size)

        for epoch in range(self.epochs):
            print(f"Epoch {epoch + 1}/{self.epochs}")
            train_loss = self.train_epoch(train_dataloader)
            val_accuracy = self.evaluate(val_dataloader)

            print(f"Train Loss: {train_loss}, Validation Accuracy: {val_accuracy}")

            if val_accuracy > self.best_val_accuracy:
                print("Validation accuracy improved, saving model...")
                self.best_val_accuracy = val_accuracy
                self.model.save_pretrained(self.save_path)
                self.tokenizer.save_pretrained(self.save_path)

    def load_best_model(self):
        self.model = AutoModelForSequenceClassification.from_pretrained(self.save_path).to(self.device)

if __name__ == '__main__':
    tokenizer = AutoTokenizer.from_pretrained("roberta-large")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    train_dataset = StratifiedDatabaseMalwareDataset(tokenizer=tokenizer, split='train', max_length=512)

    model = AutoModelForSequenceClassification.from_pretrained("roberta-large",
                                                               num_labels=train_dataset.get_num_labels())  # Ensure num_labels is correctly defined

    val_dataset = StratifiedDatabaseMalwareDataset(tokenizer=tokenizer, split='validation', max_length=512)

    # Initialize and run the custom trainer
    custom_trainer = CustomTrainer(model, train_dataset, val_dataset, tokenizer, device)
    custom_trainer.train()
