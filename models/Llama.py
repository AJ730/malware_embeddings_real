import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, \
    EarlyStoppingCallback
from sklearn.metrics import accuracy_score

from utils.database_utils.DatabaseMalwareDataset import StratifiedDatabaseMalwareDataset


# Initialize the tokenizer
tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-2-7b-hf", token='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')

train_dataset = StratifiedDatabaseMalwareDataset(tokenizer=tokenizer,  split='train', max_length=4096)
val_dataset = StratifiedDatabaseMalwareDataset(tokenizer=tokenizer,  split='validation', max_length=4096)

# Define the model
model = AutoModelForSequenceClassification.from_pretrained("meta-llama/Llama-2-7b-hf", token= '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', num_labels=train_dataset.get_num_labels())

# Define compute_metrics function for evaluation
def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    acc = accuracy_score(labels, preds)
    return {'accuracy': acc}


if __name__ == '__main__':

    # Define training arguments
    # Update TrainingArguments to log validation accuracy every 10 steps
    training_args = TrainingArguments(
        output_dir='./results',
        num_train_epochs=3,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        warmup_steps=500,
        weight_decay=0.01,
        logging_dir='./logs',
        logging_steps=10,  # Log training info every 10 steps
        evaluation_strategy="steps",
        eval_steps=10,  # Evaluate and log accuracy on the validation set every 10 steps
        save_strategy="steps",
        save_steps=500,
        load_best_model_at_end=True,
        metric_for_best_model="accuracy",
        greater_is_better=True
    )

    # Initialize Trainer
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        compute_metrics=compute_metrics,
    )

    # Train the model
    trainer.train()
