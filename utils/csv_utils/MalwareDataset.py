import csv
import torch
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import Dataset, DataLoader
from transformers import AutoTokenizer


class MalwareDatasetCSV(Dataset):
    def __init__(self, csv_file, tokenizer, max_length=512):
        self.data = []
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.label_encoder = LabelEncoder()

        # Temporarily store family names to fit LabelEncoder
        family_names = []
        with open(csv_file, newline='', encoding='utf-8') as csvfile:
            reader = csv.DictReader(csvfile)
            for row in reader:
                family_names.append(row['family_name'])

        # Fit LabelEncoder on all family names
        self.label_encoder.fit(family_names)

        # Re-open the file to load data and encode family names
        with open(csv_file, newline='', encoding='utf-8') as csvfile:
            reader = csv.DictReader(csvfile)
            for row in reader:
                encoded_family_name = self.label_encoder.transform([row['family_name']])[0]
                self.data.append((row['sha'], row['llm_text'], encoded_family_name))

    def __getitem__(self, idx):
        sha, llm_text, encoded_family_name = self.data[idx]
        inputs = self.tokenizer(llm_text, max_length=self.max_length, padding='max_length', truncation=True,
                                return_tensors="pt")

        input_ids = inputs['input_ids'].squeeze()
        attention_mask = inputs['attention_mask'].squeeze()
        target = torch.tensor(encoded_family_name, dtype=torch.long)

        return {"input_ids": input_ids, "attention_mask": attention_mask, "target": target, "sha": sha}


